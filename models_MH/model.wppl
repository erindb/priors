
// time webppl model.wppl --require priorUtils

// notes
// - how do log probabilities compare between the dependent measures?

// to do
// - add subject-wise variables
// - posteriors predictives

var data_numberChoice = dataFrame(
			priorUtils.readCSV('../prag/data/number_dat.csv'),
	["workerid","response","max","chosen_bin","chosen_min",
			"chosen_max","steps"])
var data_sliderBins = dataFrame(
			priorUtils.readCSV('../prag/data/bin_dat_noZeros.csv'),
	["workerid","bin_num","response","nresponse"])
var data_lightning = dataFrame(
			priorUtils.readCSV('../prag/data/choice_dat.csv'),
	["workerid", "chosen_tag", "unchosen_tag", "chosen_bin", 
						"unchosen_bin", "chosen_higher"])

var items = _.uniq(_.pluck(data_numberChoice, "tag"))
var subjects = _.uniq(_.pluck(data_numberChoice, "workerid"))

var model = function(){

	foreach(items,function(i){

		// var t0 = priorUtils.getTime()
		var priors = dirichlet([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1])

		var itemNumberData = subset(data_numberChoice, "tag", i)
		var itemSliderData = subset(data_sliderBins, "tag", i)
		var itemLightningData = subset(data_lightning, "tag", i)

		foreach(subjects,function(s){

			var subjectivePriors = priors

			// give a number task data
			// var numberDatum = subset(itemNumberData, 
			// 						"workerid", s)[0]["chosen_bin"]
			// var numberScr = discreteERP.score([subjectivePriors], 
			// 									numberDatum-1)

			// binned histogram task data
			var sliderData = _.pluck(
				_.sortBy(subset(itemSliderData, "workerid", s), "bin_num"),
				"nresponse")
			var sliderScr = dirichletERP.score(subjectivePriors, sliderData)

			var lightningScr = 0
			var numberScr = 0
			// lightning round task data
			// var lightningData = subset(itemLightningData, "workerid", s)
			// var lightningScr = reduce(function(d, memo){
			// 	var chosenWeight = subjectivePriors[d["chosen_bin"] - 1]
			// 	var unchosenWeight = subjectivePriors[d["unchosen_bin"] - 1]
			// 	var normalizedWeights = [chosenWeight/
			// 								(chosenWeight+unchosenWeight),
			// 							unchosenWeight/
			// 								(chosenWeight+unchosenWeight)]
			// 	var coinWeight = (1 + normalizedWeights[0] - 
			// 						  normalizedWeights[1] ) / 2

			// 	return memo + bernoulliERP.score([coinWeight],true)
			// }, 0, lightningData)

			console.log(lightningScr+sliderScr+numberScr)
			factor(lightningScr+sliderScr+numberScr)


			// posterior predictives

			// var ppNumber = discrete(subjectivePriors)
			var ppBins = dirichlet(subjectivePriors)
			console.log(ppBins)

			// query.add(["predictive", "number",s,i, "NA", "NA"], ppNumber)
			// query.add(["predictive", "binned",s,i, "NA", "NA"], ppBins)
			// foreach(lightningData, function(d){
			// 	var chosenWeight = subjectivePriors[d["chosen_bin"] - 1]
			// 	var unchosenWeight = subjectivePriors[d["unchosen_bin"] - 1]
			// 	var normalizedWeights = [chosenWeight/
			// 								(chosenWeight+unchosenWeight),
			// 							unchosenWeight/
			// 								(chosenWeight+unchosenWeight)]
			// 	var coinWeight = (1 + normalizedWeights[0] - 
			// 						  normalizedWeights[1] ) / 2
			// 	query.add(["predictive", "lightning",s,i, d["chosen_bin"], d["unchosen_bin"]], 
			// 					flip(coinWeight))
			// })

		})
	
		// console.log(t1-t0)
		// foreach(_.zip(_.range(0,15), priors), function(p){
		// 	query.add(["posterior","priorVector","NA", i, "NA", p[0]], p[1])
		// })

	})

	return query
}


// data_sliderBins
// data_lightning
var inference = "IncrMH"
var samples = 10000
var burn = samples/2

// var resultsERP = IncrementalMH(model, samples, 
// 	{verbose:true, verboseLag: samples/20, burn:burn})

var resultsERP = MCMC(model,  
	{samples: samples, verbose:true, burn:burn})

console.log('inference complete. writing results to file...')

var outputFile = "results/priors-base-" + inference + samples + "burn" + burn + ".csv"

var header = 'Type,Parameter,Subject,Item,chosenBin, unchosenBin'
priorUtils.erpWriter(resultsERP, outputFile, header)
console.log('output written to ' + outputFile)